{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gordon-4389/Face-Anonymisation-Benchmarking/blob/main/Exp_3_1_GANonymisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUWvRx4dhiLZ"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTFw_8lrlN_a",
        "outputId": "c354c67d-7f95-48d8-d614-ba0f33126d19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchrl\n",
            "  Downloading torchrl-0.3.1-cp310-cp310-manylinux1_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.2.2-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.17.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchrl) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchrl) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchrl) (24.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from torchrl) (2.2.1)\n",
            "Collecting tensordict>=0.3.1 (from torchrl)\n",
            "  Downloading tensordict-0.3.2-cp310-cp310-manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch>=2.1.0 (from torchrl)\n",
            "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1.0->torchrl)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1.0->torchrl)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1.0->torchrl)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.1.0->torchrl)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1.0->torchrl)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1.0->torchrl)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1.0->torchrl)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1.0->torchrl)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1.0->torchrl)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=2.1.0->torchrl)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1.0->torchrl)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.0->torchrl)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->torchrl) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.0->torchrl) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchtext, torchaudio, tensordict, torchrl\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.17.1+cu121\n",
            "    Uninstalling torchvision-0.17.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.17.1+cu121\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.17.1\n",
            "    Uninstalling torchtext-0.17.1:\n",
            "      Successfully uninstalled torchtext-0.17.1\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.2.1+cu121\n",
            "    Uninstalling torchaudio-2.2.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.2.1+cu121\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 tensordict-0.3.2 torch-2.2.2 torchaudio-2.2.2 torchrl-0.3.1 torchtext-0.17.2 torchvision-0.17.2\n"
          ]
        }
      ],
      "source": [
        "# @title Install Tensorflow and Related\n",
        "# Install Torch Tensorflow and TensorRT\n",
        "# Install TensorRT\n",
        "!pip install torchrl torchvision torchaudio torchtext torchdata -U\n",
        "# !pip install tensorflow[and-cuda] --quiet\n",
        "# !pip install tensorrt --quiet\n",
        "# !pip install --upgrade --no-cache-dir gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V80m4tFhgOar",
        "outputId": "e300ef46-0902-4338-ca72-b1e7156b9531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "We got a GPU\n"
          ]
        }
      ],
      "source": [
        "# @title Check GPU Exists\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(physical_devices)\n",
        "if len(physical_devices) > 0:\n",
        "    print(\"We got a GPU\")\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "else:\n",
        "    print(\"Sorry, no GPU for you...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ES0mNkSP6u7b"
      },
      "outputs": [],
      "source": [
        "# @title Code to replace setup dependencies (Redundant as of Last Update 13/03/24)\n",
        "\n",
        "# function to replace strings in the code\n",
        "def replace_string_txt_file(to_sub_string: str, replace_string: str, file_path: str):\n",
        "    with open(file_path, 'r') as file:\n",
        "        filedata = file.read()\n",
        "\n",
        "    filedata = filedata.replace(to_sub_string, replace_string) # Reokace String\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(filedata)\n",
        "    return\n",
        "\n",
        "# # Fix statsmodels - 0.13.5 -> 0.14.0\n",
        "# # Should be fine to do so, seeing that there are no changes: https://github.com/statsmodels/statsmodels/compare/v0.14.0...v0.13.5?diff=unified&w=\n",
        "# replace_string_txt_file('statsmodels==0.13.5','statsmodels>=0.14.0,', 'GANonymization/requirements.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJrO2o5G4hws",
        "outputId": "9e3a4e9c-7194-4248-b8dd-cb5c34d08165"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GANonymization'...\n",
            "remote: Enumerating objects: 361, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 361 (delta 26), reused 12 (delta 12), pack-reused 308\u001b[K\n",
            "Receiving objects: 100% (361/361), 121.20 KiB | 5.51 MiB/s, done.\n",
            "Resolving deltas: 100% (205/205), done.\n"
          ]
        }
      ],
      "source": [
        "# @title Download GANonymization\n",
        "!rm -rf GANonymization\n",
        "!git clone https://github.com/hcmlab/GANonymization.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbKK3RFl7naP",
        "outputId": "b6daf58a-ed7b-4ac3-86f4-e2bb07b31f68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.6/801.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.3/94.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for GANonymization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for p_tqdm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for head-segmentation (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# @title Install GANonymization\n",
        "! pip install git+https://github.com/hcmlab/GANonymization --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IypCe5JBd5w-"
      },
      "source": [
        "# Get Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUj18tlwxDkR",
        "outputId": "0f791981-c111-4c2e-ea37-f90a7ae84ec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 1/1 [00:05<00:00,  5.16s/it]\n",
            "100% 1/1 [00:03<00:00,  3.40s/it]\n"
          ]
        }
      ],
      "source": [
        "# @title Get Data and Pre-trained Models from Google Drive\n",
        "import gdown, os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "# Mount Drive and Get Data\n",
        "# drive.mount('/content/drive', force_remount=False) # Mount Google Drive Manually\n",
        "# !rm -rf Testing_Dataset_20k # Optional\n",
        "shutil.unpack_archive('/content/drive/MyDrive/Testing_Dataset_20k/test_dataset_20k_fdf256.zip', '/content/Testing_Dataset_20k/test_dataset_20k_fdf256')\n",
        "shutil.unpack_archive('/content/drive/MyDrive/Testing_Dataset_20k/test_dataset_20k_CelebA-HQ.zip', '/content/Testing_Dataset_20k/test_dataset_20k_CelebA-HQ')\n",
        "\n",
        "# Get Model\n",
        "os.makedirs(\"/content/model\", exist_ok=True)\n",
        "urlretrieve(\"https://mediastore.rz.uni-augsburg.de/get/NsLjQYey65/\", \"/content/model/GANonymization_25.ckpt\")\n",
        "urlretrieve(\"https://mediastore.rz.uni-augsburg.de/get/Sfle_etB1D/\", \"/content/model/GANonymization_50.ckpt\")\n",
        "# update checkpoints\n",
        "!python -m pytorch_lightning.utilities.upgrade_checkpoint /content/model/GANonymization_25.ckpt\n",
        "!python -m pytorch_lightning.utilities.upgrade_checkpoint /content/model/GANonymization_50.ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTdZ3FOhOEfG"
      },
      "source": [
        "# Running GANonymization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hSBU7Bn9RRd5",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f508fbdc-9b17-4669-cd0d-e9fd4c40ca88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Path: /content/model/GANonymization_25.ckpt\n",
            "Testing folder_path: /content/Testing_Dataset_20k/test_dataset_20k_CelebA-HQ\n"
          ]
        }
      ],
      "source": [
        "# @title Select Model to Run\n",
        "model = \"GANonymization_25\" # @param [\"GANonymization_25\", \"GANonymization_50\"]\n",
        "dataset = \"CelebA-HQ\" # @param [\"fdf256\", \"CelebA-HQ\"]\n",
        "print(f\"Model Path: /content/model/{model}.ckpt\")\n",
        "print(f\"Testing folder_path: /content/Testing_Dataset_20k/test_dataset_20k_{dataset}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copying Partial Results if Any\n",
        "print(\"Copying Partial Results\")\n",
        "try:\n",
        "  !cp -r /content/drive/MyDrive/Testing_Dataset_20k/{dataset}_GANonymization  /content/Testing_Dataset_20k/{dataset}_{model}\n",
        "except:\n",
        "  print(\"No Partial Results\")"
      ],
      "metadata": {
        "id": "mHTd2_2mFfEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c412b27-3937-4536-e073-a1152a2c3cdb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying Partial Results\n",
            "cp: cannot stat '/content/drive/MyDrive/Testing_Dataset_20k/CelebA-HQ_GANonymization': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEdJQjZBtOqd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        " # @title Run GANonymization (25) on single image\n",
        "!python /content/GANonymization/main.py anonymize_image --model_file /content/model/GANonymization_25.ckpt --input_file  /content/Testing_Dataset_20k/test_dataset_20k_fdf256/066554.png --output_file /content/anon_066554.png\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "img = imageio.imread('/content/Testing_Dataset_20k/test_dataset_20k_fdf256/066554.png')\n",
        "img2 = imageio.imread('/content/anon_066554.png')\n",
        "plt.imshow(img, img2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA9OUdtiSbk9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae2b290-8e4d-438c-f173-ee44a9ff0885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Model: GANonymization_25.ckpt on Dataset: CelebA-HQ\n",
            "2024-04-07 15:47:22.710631: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-07 15:47:22.710781: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-07 15:47:22.853799: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-07 15:47:25.498878: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Anonymizing from /content/Testing_Dataset_20k/test_dataset_20k_CelebA-HQ:   0% 0/20000 [00:00<?, ?it/s]2024-04-07 15:47:30.561829: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "24-04-07 15:47:33 - Directory /root/.deepface created\n",
            "24-04-07 15:47:33 - Directory /root/.deepface/weights created\n",
            "24-04-07 15:47:33 - retinaface.h5 will be downloaded from the url https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "To: /root/.deepface/weights/retinaface.h5\n",
            "\n",
            "  0% 0.00/119M [00:00<?, ?B/s]\u001b[A\n",
            "  1% 1.57M/119M [00:00<00:08, 14.0MB/s]\u001b[A\n",
            "  6% 7.34M/119M [00:00<00:02, 37.5MB/s]\u001b[A\n",
            " 18% 21.0M/119M [00:00<00:01, 77.3MB/s]\u001b[A\n",
            " 39% 46.1M/119M [00:00<00:00, 142MB/s] \u001b[A\n",
            " 68% 80.2M/119M [00:00<00:00, 210MB/s]\u001b[A\n",
            "100% 119M/119M [00:00<00:00, 185MB/s]\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "Anonymizing from /content/Testing_Dataset_20k/test_dataset_20k_CelebA-HQ:  64% 12859/20000 [5:38:08<3:04:20,  1.55s/it]"
          ]
        }
      ],
      "source": [
        "# @title Anonymise Base on Directory\n",
        "import shutil, os\n",
        "\n",
        "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH '] = '0'\n",
        "\n",
        "print(f\"Running Model: {model}.ckpt on Dataset: {dataset}\")\n",
        "\n",
        "# Run pretrained model on data\n",
        "output_path = f\"/content/{dataset}_{model}\"\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "!rm -rf {output_path}\n",
        "# Run pretrained model on data\n",
        "!python /content/GANonymization/main.py anonymize_directory --model_file /content/model/{model}.ckpt --input_directory /content/Testing_Dataset_20k/test_dataset_20k_{dataset} --output_directory {output_path}\n",
        "\n",
        "# Check Output Results Results\n",
        "if len(os.listdir(output_path)) >= 20000:\n",
        "  print(\"Saving Results\")\n",
        "  shutil.make_archive(output_path, 'zip', output_path)\n",
        "else:\n",
        "  print(\"ERROR: Not enough Images in \", output_path,\"!!! - size:\", len(os.listdir(output_path)) )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0QQGh1v1G2B",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Directory Anonymisation: Manual\n",
        "import glob\n",
        "import os\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
        "count = 0\n",
        "\n",
        "input_images = glob.glob(f'/content/Testing_Dataset_20k/test_dataset_20k_{dataset}/*.*')\n",
        "output_path = f\"/content/{dataset}_{model}\"\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "print(\"input folder size:\", len(input_images))\n",
        "check_output = glob.glob(output_path+'/*.*')\n",
        "print(\"output folder size:\", len(check_output))\n",
        "\n",
        "for image in input_images:\n",
        "  # clear_output(wait=True) # Clear output\n",
        "  image_num = image.split('/')[-1]\n",
        "  o_path = os.path.join(output_path, image_num)\n",
        "  print(o_path)\n",
        "  if o_path not in check_output:\n",
        "    ! python3 /content/GANonymization/main.py anonymize_image --model_file /content/model/{model}.ckpt --input_file {image} --output_file {o_path} --quiet\n",
        "    count += 1\n",
        "    print(count)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Upload to Drive\n",
        "%cd ~/../content/\n",
        "path = f'/content/{dataset}_{model}'\n",
        "print(len(os.listdir(path)))\n",
        "# !cp -r /content/Testing_Dataset_20k/test_dataset_20k_CelebA-HQ /content/drive/MyDrive/Testing_Dataset_20k/\n",
        "# !cp -r /content/Testing_Dataset_20k/test_dataset_20k_fdf256 /content/drive/MyDrive/Testing_Dataset_20k/\n",
        "!cp -r {path} /content/drive/MyDrive/Testing_Dataset_20k/"
      ],
      "metadata": {
        "id": "KbyDX5hRM2JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ4WbqJ6kosi",
        "outputId": "ea3a6627-9fbc-4188-bd69-86e3772158a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "# @title Debugging:\n",
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ul65XW0nPGT",
        "outputId": "a62e9a11-066a-417d-9b6d-b78c259a02f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda: /usr/local/cuda\n",
            "cat: /usr/local/cuda/include/cudnn.h: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!whereis cuda\n",
        "!cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i52Oc5-QpezV",
        "outputId": "6c855f3c-f180-447d-831b-2e7519300c05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.__version__ - 2.1.0+cu121\n",
            "torch.cuda.is_available - True\n",
            "torch.cuda.get_device_name - Tesla V100-SXM2-16GB\n",
            "torch.backends.cuda.is_built - True\n",
            "torch.backends.cuda.matmul.allow_tf32 - False\n",
            "torch.backends.cudnn.version - 8902\n",
            "torch.backends.cudnn.enabled - True\n",
            "torch.backends.cudnn.benchmark - False\n",
            "torch.backends.cudnn.deterministic - False\n",
            "torch.backends.cudnn.allow_tf32 - True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"torch.__version__ - {torch.__version__}\")\n",
        "print(f\"torch.cuda.is_available - {torch.cuda.is_available()}\")\n",
        "print(f\"torch.cuda.get_device_name - {torch.cuda.get_device_name()}\")\n",
        "print(f\"torch.backends.cuda.is_built - {torch.backends.cuda.is_built()}\")\n",
        "print(f\"torch.backends.cuda.matmul.allow_tf32 - {torch.backends.cuda.matmul.allow_tf32}\")\n",
        "print(f\"torch.backends.cudnn.version - {torch.backends.cudnn.version()}\")\n",
        "print(f\"torch.backends.cudnn.enabled - {torch.backends.cudnn.enabled}\")\n",
        "print(f\"torch.backends.cudnn.benchmark - {torch.backends.cudnn.benchmark}\")\n",
        "print(f\"torch.backends.cudnn.deterministic - {torch.backends.cudnn.deterministic}\")\n",
        "print(f\"torch.backends.cudnn.allow_tf32 - {torch.backends.cudnn.allow_tf32}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kyVskxXJdUp",
        "outputId": "29fb0cc1-77b0-4757-9106-e5dff55013ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-13 00:32:36.701684: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-13 00:32:36.701734: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-13 00:32:36.703088: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-13 00:32:37.943161: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-13 00:32:41.230548: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "24-03-13 00:32:43 - Directory /root/.deepface created\n",
            "24-03-13 00:32:43 - Directory /root/.deepface/weights created\n",
            "24-03-13 00:32:43 - retinaface.h5 will be downloaded from the url https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "To: /root/.deepface/weights/retinaface.h5\n",
            "100% 119M/119M [00:00<00:00, 143MB/s]\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.makedirs(\"/content/data\", exist_ok=True)\n",
        "os.makedirs(\"/content/model\", exist_ok=True)\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "urlretrieve(\"https://mediastore.rz.uni-augsburg.de/get/NsLjQYey65/\", \"/content/model/GANonymization_25.ckpt\")\n",
        "urlretrieve(\"https://upload.wikimedia.org/wikipedia/commons/8/8d/President_Barack_Obama.jpg\", \"/content/data/President_Barack_Obama.jpg\")\n",
        "\n",
        "!python /content/GANonymization/main.py anonymize_image --model_file /content/model/GANonymization_25.ckpt --input_file /content/data/President_Barack_Obama.jpg --output_file /content/output/President_Barack_Obama.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81ql_3DjM6zn",
        "outputId": "f3aa1c4c-4c8f-4040-fb45-c21a0b98d1c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-13 00:48:25.507086: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-13 00:48:25.507143: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-13 00:48:25.508586: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-13 00:48:26.828215: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-13 00:48:29.527501: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        }
      ],
      "source": [
        "!python /content/GANonymization/main.py anonymize_image --model_file /content/model/GANonymization_25.ckpt --input_file /content/data/President_Barack_Obama.jpg --output_file /content/output/President_Barack_Obama.jpg"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "mount_file_id": "1lKjk8OnByJzPwcJ03OVJ9sw12tX-vcc9",
      "authorship_tag": "ABX9TyMorobe0dTBoCz40up1goaC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}